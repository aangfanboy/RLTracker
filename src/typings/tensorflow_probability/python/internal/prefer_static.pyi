"""
This type stub file was generated by pyright.
"""

"""Operations that use static values when possible."""
JAX_MODE = ...
def smart_where(condition, x_fn, y_fn):
  """As tf.where, but only calls x_fn/y_fn when condition not statically known.

  IMPORTANT: Since this avoids executing the inoperative branch when possible,
  it will not necessarily broadcast `x_fn()` with `y_fn()`, so it is imperative
  that they return `Tensor`s which broadcast with `condition` to the same final
  shape.

  Args:
    condition: A `bool` Tensor.
    x_fn: A callable returning a `Tensor`, for locations where `condition` is
      `True`.
    y_fn: A callable returning a `Tensor`, for locations where `condition` is
      `False`.

  Returns:
    A `Tensor` equivalent to `tf.where(condition, x_fn(), y_fn())`.
  """
  ...

def rank_from_shape(shape_tensor_fn, tensorshape=...): # -> int32:
  """Computes `rank` given a `Tensor`'s `shape`."""
  ...

def broadcast_shape(x_shape, y_shape):
  """Computes the shape of a broadcast.

  When both arguments are statically-known, the broadcasted shape will be
  computed statically and returned as a `TensorShape`.  Otherwise, a rank-1
  `Tensor` will be returned.

  Args:
    x_shape: A `TensorShape` or rank-1 integer `Tensor`.  The input `Tensor` is
      broadcast against this shape.
    y_shape: A `TensorShape` or rank-1 integer `Tensor`.  The input `Tensor` is
      broadcast against this shape.

  Returns:
    shape: A `TensorShape` or rank-1 integer `Tensor` representing the
      broadcasted shape.
  """
  ...

def cond(pred, true_fn=..., false_fn=..., name=...): # -> object:
  """Return either `true_fn()` if predicate `pred` is true else `false_fn()`.

  If `pred` is a bool or has a constant value, we return either `true_fn()`
  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.

  Args:
    pred: A scalar determining whether to return the result of `true_fn` or
      `false_fn`.
    true_fn: The callable to be performed if pred is true.
    false_fn: The callable to be performed if pred is false.
    name: Optional name prefix when using `tf.cond`.

  Returns:
    Tensors returned by the call to either `true_fn` or `false_fn`.

  Raises:
    TypeError: If `true_fn` or `false_fn` is not callable.
  """
  ...

def case(pred_fn_pairs, default=..., exclusive=..., name=...):
  """Like tf.case, except attempts to statically evaluate predicates.

  If any predicate in `pred_fn_pairs` is a bool or has a constant value, the
  associated callable will be called or omitted depending on its value.
  Otherwise this functions like tf.case.

  Args:
    pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a
                   callable which returns a list of tensors.
    default: Optional callable that returns a list of tensors.
    exclusive: True iff at most one predicate is allowed to evaluate to `True`.
    name: A name for this operation (optional).

  Returns:
    The tensors returned by the first pair whose predicate evaluated to True, or
    those returned by `default` if none does.

  Raises:
    TypeError: If `pred_fn_pairs` is not a list/dictionary.
    TypeError: If `pred_fn_pairs` is a list but does not contain 2-tuples.
    TypeError: If `fns[i]` is not callable for any i, or `default` is not
               callable.
  """
  ...

def size0(x, name=...): # -> int32 | Any:
  """Returns the size of the first dimension (0 if scalar)."""
  ...

def dimension_size(x, idx): # -> ndarray[_Shape, dtype[Any]] | Any:
  """Equivalent to `shape(x)[idx]`, but robust to partially-known shapes."""
  ...

def shape_slice(x, slice_): # -> ndarray[_Shape, dtype[Any]] | Any:
  """Equivalent to `shape(x)[slice_]`, but robust to partially-known shapes."""
  ...

ones_like = ...
rank = ...
setdiff1d = ...
size = ...
shape = ...
zeros_like = ...
def non_negative_axis(axis, rank, name=...): # -> NDArray[Any] | None:
  """Make (possibly negatively indexed) `axis` argument non-negative."""
  ...

def is_numpy(x): # -> bool:
  """Returns true if `x` is a numpy object."""
  ...

_slice = slice
abs = ...
add = ...
argmax = ...
argmin = ...
argsort = ...
broadcast_to = ...
cast = ...
ceil = ...
concat = ...
convert_to_shape_tensor = ...
constant = ...
cumprod = ...
cumsum = ...
equal = ...
not_equal = ...
expand_dims = ...
expm1 = ...
eye = ...
floor = ...
fill = ...
gather = ...
greater = ...
identity = ...
invert_permutation = ...
is_finite = ...
is_inf = ...
is_nan = ...
less = ...
linspace = ...
log = ...
log1p = ...
logical_and = ...
logical_not = ...
logical_or = ...
maximum = ...
minimum = ...
nextafter = ...
one_hot = ...
ones = ...
pad = ...
pow = ...
range = ...
reduce_all = ...
reduce_any = ...
reduce_max = ...
reduce_min = ...
reduce_prod = ...
reduce_sum = ...
repeat = ...
reshape = ...
reverse = ...
round = ...
rsqrt = ...
slice = ...
sort = ...
split = ...
sqrt = ...
stack = ...
tensor_scatter_nd_add = ...
tensor_scatter_nd_sub = ...
tensor_scatter_nd_update = ...
tile = ...
top_k = ...
unique = ...
unstack = ...
where = ...
zeros = ...
