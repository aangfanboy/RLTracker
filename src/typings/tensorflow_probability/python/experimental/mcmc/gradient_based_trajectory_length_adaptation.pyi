"""
This type stub file was generated by pyright.
"""

import collections
from tensorflow_probability.python.mcmc import kernel as kernel_base
from tensorflow_probability.python.mcmc.internal import util as mcmc_util

"""Gradient-based trajectory length adaptation kernel."""
__all__ = ['chees_criterion', 'chees_rate_criterion', 'GradientBasedTrajectoryLengthAdaptation', 'GradientBasedTrajectoryLengthAdaptationResults', 'snaper_criterion']
MAX_HALTON_SEQUENCE_BITS = ...
class GradientBasedTrajectoryLengthAdaptationResults(mcmc_util.PrettyNamedTupleMixin, collections.namedtuple('GradientBasedTrajectoryLengthAdaptationResults', ['inner_results', 'max_trajectory_length', 'step', 'adaptation_rate', 'jitter_amount', 'averaged_sq_grad', 'averaged_sq_grad_adaptation_rate', 'averaged_max_trajectory_length', 'criterion', 'seed'])):
  """Internal state of GradientBasedTrajectoryLengthAdaptation.

  Attributes:
    inner_results: Results of the inner kernel.
    max_trajectory_length: Floating point scalar `Tensor`. Maximum HMC
      trajectory length.
    step: Int32 scalar `Tensor`. The number of steps this kernel has taken.
      Increases by 1 for every call to `one_step`.
    adaptation_rate: Floating point scalar `Tensor`. How rapidly to adapt the
      trajectory length.
    jitter_amount: Floating point scalar `Tensor`. How much to jitter the
      trajectory on the next step. The trajectory length is sampled from `[(1 -
      jitter_amount) * max_trajectory_length, max_trajectory_length]`.
    averaged_sq_grad: Floating point scalar `Tensor`. Moving average of squared
      criterion gradients.
    averaged_sq_grad_adaptation_rate: Floating point scalar `Tensor`. How
      rapidly to adapt the running average squared gradient. This is `1 -
      beta_2` from Adam.
    averaged_max_trajectory_length: Floating point scalar `Tensor`. Moving
      average of the maximum of trajectory length. This is used after the burnin
      period.
    criterion: Floating point `Tensor` with shape `[C0, ..., Cb]` with `b > 0`.
      The value of the criterion returned by the `criterion_fn` corresponding to
      each Markov chain.
    seed: PRNG seed; see `tfp.random.sanitize_seed` for details. The random seed
      used by the kernel in the previous step.
  """
  __slots__ = ...


_reduce_sum_with_axes = ...
_reduce_mean_with_axes = ...
def hmc_like_num_leapfrog_steps_getter_fn(kernel_results):
  """Getter for `num_leapfrog_steps` so it can be inspected."""
  ...

def hmc_like_num_leapfrog_steps_setter_fn(kernel_results, new_num_leapfrog_steps):
  """Setter for `num_leapfrog_steps` so it can be adapted."""
  ...

hmc_like_proposed_velocity_getter_fn = ...
hmc_like_initial_velocity_getter_fn = ...
def hmc_like_proposed_state_getter_fn(kernel_results):
  """Getter for `proposed_state` so it can be inspected."""
  ...

def hmc_like_step_size_getter_fn(kernel_results):
  ...

def hmc_like_log_accept_prob_getter_fn(kernel_results):
  ...

def chees_criterion(previous_state, proposed_state, accept_prob, trajectory_length, forward=..., validate_args=..., experimental_shard_axis_names=..., experimental_reduce_chain_axis_names=...):
  """The ChEES criterion from [1].

  ChEES stands for Change in the Estimator of the Expected Square.

  ```None
  ChEES = 1/4 E[(||x' - E[x]||**2 - ||x - E[x]||**2)**2],
  ```

  where `x` is the previous chain state, `x'` is the next chain state, and
  `||.||` is the L2 norm. Both expectations are with respect to the chain's
  stationary distribution. In practice, the inner expectation is replaced by the
  empirical mean across chains, so computing this criterion requires that at
  least 2 chains are present. The outer expectation is computed by the caller
  (e.g. in the `GradientBasedTrajectoryLengthAdaptation` kernel).

  This can be thought of as the standard expected squared jump distance (ESJD)
  criterion, except that the jump distance is computed in the space of centered
  squared L2 norms.

  Unlike ChEES, regular ESJD is maximized by perfectly anticorrelated proposals,
  which can give excellent mean estimates but terrible variance estimates;
  maximizing ChEES should give good estimates across a wider range of types of
  posterior expectations.

  Args:
    previous_state: (Possibly nested) floating point `Tensor`. The previous
      state of the HMC chain.
    proposed_state: (Possibly nested) floating point `Tensor`. The proposed
      state of the HMC chain.
    accept_prob: Floating `Tensor`. Probability of acceping the proposed state.
    trajectory_length: Floating `Tensor`. Mean trajectory length (not used in
      this criterion).
    forward: Whether accept_prob refers to the proposed_state (True) or the
      previous_state (False).
    validate_args: Whether to perform non-static argument validation.
    experimental_shard_axis_names: A structure of string names indicating how
      members of the state are sharded.
    experimental_reduce_chain_axis_names: A string or list of string names
      indicating which named chain axes to reduce over when computing the
      criterion.

  Returns:
    chees: The value of the ChEES criterion.

  Raises:
    ValueError: If `accept_prob` indicates that there are fewer than 2 chains.

  #### References

  [1]: Hoffman, M., Radul, A., & Sountsov, P. (2020). An Adaptive MCMC Scheme
       for Setting Trajectory Lengths in Hamiltonian Monte Carlo.
       <https://proceedings.mlr.press/v130/hoffman21a>

  """
  ...

def chees_rate_criterion(previous_state, proposed_state, accept_prob, trajectory_length, forward=..., validate_args=..., experimental_shard_axis_names=..., experimental_reduce_chain_axis_names=...):
  """ChEES rate criterion.

  This is just like `chees_criterion`, but normalized by the trajectory
  length:
  ```none
  ChEES rate = 1/4 E[(||x' - E[x]||**2 - ||x - E[x]||**2)**2 /
    trajectory_length]
  ```

  Args:
    previous_state: (Possibly nested) floating point `Tensor`. The previous
      state of the HMC chain.
    proposed_state: (Possibly nested) floating point `Tensor`. The proposed
      state of the HMC chain.
    accept_prob: Floating `Tensor`. Probability of acceping the proposed state.
    trajectory_length: Floating `Tensor`. Trajectory length.
    forward: Whether accept_prob refers to the proposed_state (True) or the
      previous_state (False).
    validate_args: Whether to perform non-static argument validation.
    experimental_shard_axis_names: A structure of string names indicating how
      members of the state are sharded.
    experimental_reduce_chain_axis_names: A string or list of string names
      indicating which named chain axes to reduce over when computing the
      criterion.

  Returns:
    chees_rate: The value of the ChEES rate criterion.
  """
  ...

def snaper_criterion(previous_state, proposed_state, accept_prob, trajectory_length, direction, state_mean=..., state_mean_weight=..., forward=..., validate_args=..., experimental_shard_axis_names=..., experimental_reduce_chain_axis_names=...):
  """The SNAPER criterion from [1].

  SNAPER stands for Squared Norm Along Principal component ESJD Rate:

  ```None
  SNAPER = E[(((x' - E[x'])^T p)**2 - ((x' - E[x])^T p)**2)**2 /
             trajectory_length],
  ```

  where `x` is the previous chain state, `x'` is the next chain state, and `p`
  is a unit vector (the `direction` argument). Both expectations are with
  respect to the chain's stationary distribution. In practice, the inner
  expectation is replaced by the empirical mean across chains, so computing this
  criterion requires that at least 2 chains are present unless `state_mean` and
  `state_mean_weight` are set. The outer expectation is computed by the caller
  (e.g. in the `GradientBasedTrajectoryLengthAdaptation` kernel).

  This can be thought of as the standard expected squared jump distance (ESJD)
  criterion, except that the jump distance is computed in the space of squared
  projections onto a vector.

  The `direction` vector is typically chosen to be an approximation to the first
  principal component of the state covariance matrix.

  `state_mean` and `state_mean_weight` can be used to supplement the empirical
  means as follows:

  ```None
  E[x] â‰ˆ (1 - state_mean_weight) * x.mean() + state_mean_weight * state_mean.
  ```

  Args:
    previous_state: (Possibly nested) floating point `Tensor`. The previous
      state of the HMC chain.
    proposed_state: (Possibly nested) floating point `Tensor`. The proposed
      state of the HMC chain.
    accept_prob: Floating `Tensor`. Probability of acceping the proposed state.
    trajectory_length: Floating `Tensor`. Mean trajectory length (not used in
      this criterion).
    direction: (Possibly nested) floating point `Tensor`. A unit vector onto
      which the centered state should be projected before computing ESJD.
      Typically this chosen to be an approximation to the first principal
      component of the state covariance matrix.
    state_mean: Optional (Possibly nested) floating point `Tensor`. The
      estimated state mean.
    state_mean_weight: Floating point `Tensor`. The weight of the `state_mean`.
    forward: Whether accept_prob refers to the proposed_state (True) or the
      previous_state (False).
    validate_args: Whether to perform non-static argument validation.
    experimental_shard_axis_names: A structure of string names indicating how
      members of the state are sharded.
    experimental_reduce_chain_axis_names: A string or list of string names
      indicating which named chain axes to reduce over when computing the
      criterion.

  Returns:
    snaper: The value of the SNAPER criterion.

  #### References

  [1]: Sountsov, P. & Hoffman, M. (2021). Focusing on Difficult Directions for
       Learning HMC Trajectory Lengths. <https://arxiv.org/abs/2110.11576>

  """
  ...

class GradientBasedTrajectoryLengthAdaptation(kernel_base.TransitionKernel):
  """Use gradient ascent to adapt inner kernel's trajectory length.

  This kernel optimizes the continuous trajectory length (aka integration time)
  parameter of Hamiltonian Monte Carlo. It does so by following the gradient of
  a criterion with respect to the trajectory length. The criterion is computed
  via `criterion_fn` with signature `(previous_state, proposed_state,
  accept_prob, trajectory_length) -> criterion`, where both the returned
  values retain the batch dimensions implied by the first three inputs. See
  `chees_criterion` for an example.

  To avoid resonances, this kernel jitters the integration time between 0 and
  the learned trajectory length by default.

  The initial trajectory length is extracted from the inner
  `HamiltonianMonteCarlo` kernel by multiplying the initial step size and
  initial number of leapfrog steps. This (and other algorithmic details) imply
  that the step size must be a scalar.

  In general, adaptation prevents the chain from reaching a stationary
  distribution, so obtaining consistent samples requires `num_adaptation_steps`
  be set to a value [somewhat smaller][1] than the number of burnin steps.
  However, it may sometimes be helpful to set `num_adaptation_steps` to a larger
  value during development in order to inspect the behavior of the chain during
  adaptation.

  Optionally, it is possible to use the improved gradient estimator from [3] by
  setting `use_reverse_estimator` to `True`. This estimator relies on the
  reversibility of HMC proposal to reduce variance and thus improve the
  adaptation speed and reliability. If this is set to `true`, `criterion_fn`
  needs to also take the `forward` argument to distinguish the implied
  integration direction.

  #### Examples

  This implements something similar to ChEES HMC from [2].

  ```python
  import tensorflow as tf
  import tensorflow_probability as tfp
  tfb = tfp.bijectors
  tfd = tfp.distributions

  target_log_prob_fn = tfd.JointDistributionSequential([
      tfd.Normal(0., 20.),
      tfd.HalfNormal(10.),
  ]).log_prob

  num_burnin_steps = 1000
  num_adaptation_steps = int(num_burnin_steps * 0.8)
  num_results = 500
  num_chains = 16
  step_size = 0.1

  kernel = tfp.mcmc.HamiltonianMonteCarlo(
      target_log_prob_fn=target_log_prob_fn,
      step_size=step_size,
      num_leapfrog_steps=1,
  )
  kernel = tfp.experimental.mcmc.GradientBasedTrajectoryLengthAdaptation(
      kernel,
      num_adaptation_steps=num_adaptation_steps)
  kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(
      kernel,
      num_adaptation_steps=num_adaptation_steps,
      reduce_fn=tfp.math.reduce_log_harmonic_mean_exp)
  kernel = tfp.mcmc.TransformedTransitionKernel(
      kernel,
      [tfb.Identity(),
       tfb.Exp()])

  def trace_fn(_, pkr):
    return (
        pkr.inner_results.inner_results.inner_results.accepted_results
        .step_size,
        pkr.inner_results.inner_results.max_trajectory_length,
        pkr.inner_results.inner_results.inner_results.log_accept_ratio,
    )

  # The chain will be stepped for num_results + num_burnin_steps, adapting for
  # the first num_adaptation_steps.
  samples, [step_size, max_trajectory_length, log_accept_ratio] = (
      tfp.mcmc.sample_chain(
          num_results=num_results,
          num_burnin_steps=num_burnin_steps,
          current_state=[tf.zeros(num_chains),
                         tf.zeros(num_chains)],
          kernel=kernel,
          trace_fn=trace_fn,))

  # ~0.95, because Exp bijector is really bad for HalfNormal. Use Softplus in
  # practice.
  accept_prob = tf.math.exp(tfp.math.reduce_logmeanexp(
      tf.minimum(log_accept_ratio, 0.)))
  ```

  #### References

  [1]: <http://andrewgelman.com/2017/12/15/
        burn-vs-warm-iterative-simulation-algorithms/#comment-627745>

  [2]: Hoffman, M., Radul, A., & Sountsov, P. (2020). An Adaptive MCMC Scheme
       for Setting Trajectory Lengths in Hamiltonian Monte Carlo.
       <https://proceedings.mlr.press/v130/hoffman21a>

  [3]: Riou-Durand, L., Sountsov, P., Vogrinc, J., Margossian, C., Power, S.
       (2023) Adaptive Tuning for Metropolis Adjusted Langevin Trajectories.
       <https://proceedings.mlr.press/v206/riou-durand23a.html>

  """
  def __init__(self, inner_kernel, num_adaptation_steps, use_halton_sequence_jitter=..., adaptation_rate=..., jitter_amount=..., criterion_fn=..., max_leapfrog_steps=..., averaged_sq_grad_adaptation_rate=..., num_leapfrog_steps_getter_fn=..., num_leapfrog_steps_setter_fn=..., step_size_getter_fn=..., initial_velocity_getter_fn=..., proposed_velocity_getter_fn=..., log_accept_prob_getter_fn=..., proposed_state_getter_fn=..., use_reverse_estimator=..., validate_args=..., experimental_shard_axis_names=..., experimental_reduce_chain_axis_names=..., name=...) -> None:
    """Creates the trajectory length adaptation kernel.

    The default setter_fn and the getter_fn callbacks assume that the inner
    kernel produces kernel results structurally the same as the
    `HamiltonianMonteCarlo` kernel (possibly wrapped in some step size
    adaptation kernel).

    Args:
      inner_kernel: `TransitionKernel`-like object.
      num_adaptation_steps: Scalar `int` `Tensor` number of initial steps to
        during which to adjust the trajectory length. This may be greater, less
        than, or equal to the number of burnin steps.
      use_halton_sequence_jitter: Python bool. Whether to use a Halton sequence
        for jittering the trajectory length. This makes the procedure more
        stable than sampling trajectory lengths from a uniform distribution.
      adaptation_rate: Floating point scalar `Tensor`. How rapidly to adapt the
        trajectory length.
      jitter_amount: Floating point scalar `Tensor`. How much to jitter the
        trajectory on the next step. The trajectory length is sampled from `[(1
        - jitter_amount) * max_trajectory_length, max_trajectory_length]`.
      criterion_fn: Callable with `(previous_state, proposed_state, accept_prob)
        -> criterion`. Computes the criterion value.
      max_leapfrog_steps: Int32 scalar `Tensor`. Clips the number of leapfrog
        steps to this value.
      averaged_sq_grad_adaptation_rate: Floating point scalar `Tensor`. How
        rapidly to adapt the running average squared gradient. This is `1 -
        beta_2` from Adam.
      num_leapfrog_steps_getter_fn: A callable with the signature
        `(kernel_results) -> num_leapfrog_steps` where `kernel_results` are the
        results of the `inner_kernel`, and `num_leapfrog_steps` is a floating
        point `Tensor`.
      num_leapfrog_steps_setter_fn: A callable with the signature
        `(kernel_results, new_num_leapfrog_steps) -> new_kernel_results` where
        `kernel_results` are the results of the `inner_kernel`,
        `new_num_leapfrog_steps` is a scalar tensor `Tensor`, and
        `new_kernel_results` are a copy of `kernel_results` with the number of
        leapfrog steps set.
      step_size_getter_fn: A callable with the signature `(kernel_results) ->
        step_size` where `kernel_results` are the results of the `inner_kernel`,
        and `step_size` is a floating point `Tensor`.
      initial_velocity_getter_fn: A callable with the signature
        `(kernel_results) -> initial_velocity` where `kernel_results` are the
        results of the `inner_kernel`, and `initial_velocity` is a (possibly
        nested) floating point `Tensor`. Velocity is the derivative of state
        with respect to trajectory length.
      proposed_velocity_getter_fn: A callable with the signature
        `(kernel_results) -> proposed_velocity` where `kernel_results` are the
        results of the `inner_kernel`, and `proposed_velocity` is a (possibly
        nested) floating point `Tensor`. Velocity is the derivative of state
        with respect to trajectory length.
      log_accept_prob_getter_fn: A callable with the signature `(kernel_results)
        -> log_accept_prob` where `kernel_results` are the results of the
        `inner_kernel`, and `log_accept_prob` is a floating point `Tensor`.
        `log_accept_prob` has shape `[C0, ...., Cb]` with `b > 0`.
      proposed_state_getter_fn: A callable with the signature `(kernel_results)
        -> proposed_state` where `kernel_results` are the results of the
        `inner_kernel`, and `proposed_state` is a (possibly nested) floating
        point `Tensor`.
      use_reverse_estimator: Whether to use an improved estimator to compute
        trajectory length gradients. If `True`, `criterion_fn` needs to take a
        `forward` kwarg.
      validate_args: Python `bool`. When `True` kernel parameters are checked
        for validity. When `False` invalid inputs may silently render incorrect
        outputs.
      experimental_shard_axis_names: A structure of string names indicating how
        members of the state are sharded.
      experimental_reduce_chain_axis_names: A string or list of string names
        indicating how batches of chains are sharded.
      name: Python `str` name prefixed to Ops created by this class. Default:
        'simple_step_size_adaptation'.

    Raises:
      ValueError: If `inner_kernel` contains a `TransformedTransitionKernel` in
        its hierarchy. If you need to use the `TransformedTransitionKernel`,
        place it above this kernel in the hierarchy (see the example in the
        class docstring).
    """
    ...
  
  @property
  def inner_kernel(self): # -> None:
    ...
  
  @property
  def use_halton_sequence_jitter(self): # -> None:
    ...
  
  @property
  def num_adaptation_steps(self): # -> None:
    ...
  
  def criterion_fn(self, previous_state, proposed_state, accept_prob, trajectory_length, forward=...):
    ...
  
  @property
  def max_leapfrog_steps(self): # -> None:
    ...
  
  @property
  def averaged_sq_grad_adaptation_rate(self): # -> None:
    ...
  
  def num_leapfrog_steps_getter_fn(self, kernel_results):
    ...
  
  def num_leapfrog_steps_setter_fn(self, kernel_results, new_num_leapfrog_steps):
    ...
  
  def step_size_getter_fn(self, kernel_results):
    ...
  
  def initial_velocity_getter_fn(self, kernel_results):
    ...
  
  def proposed_velocity_getter_fn(self, kernel_results):
    ...
  
  def log_accept_prob_getter_fn(self, kernel_results):
    ...
  
  def proposed_state_getter_fn(self, kernel_results):
    ...
  
  @property
  def use_reverse_estimator(self): # -> None:
    ...
  
  @property
  def validate_args(self): # -> None:
    ...
  
  @property
  def name(self): # -> None:
    ...
  
  @property
  def parameters(self): # -> dict[str, Any | None]:
    """Return `dict` of ``__init__`` arguments and their values."""
    ...
  
  def one_step(self, current_state, previous_kernel_results, seed=...): # -> tuple[Any, Any]:
    ...
  
  def bootstrap_results(self, init_state): # -> GradientBasedTrajectoryLengthAdaptationResults:
    ...
  
  @property
  def is_calibrated(self):
    ...
  
  @property
  def experimental_shard_axis_names(self): # -> None:
    ...
  
  def experimental_with_shard_axes(self, shard_axis_names):
    ...
  
  @property
  def experimental_reduce_chain_axis_names(self): # -> None:
    ...
  


