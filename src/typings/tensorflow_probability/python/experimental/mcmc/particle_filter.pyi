"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.internal import docstring_util

"""Particle filtering."""
__all__ = ['infer_trajectories', 'particle_filter', 'reconstruct_trajectories']
_always_trace = ...
particle_filter_arg_str = ...
@docstring_util.expand_docstring(particle_filter_arg_str=particle_filter_arg_str.format(scibor_ref_idx=2))
def infer_trajectories(observations, initial_state_prior, transition_fn, observation_fn, num_particles, initial_state_proposal=..., proposal_fn=..., resample_fn=..., resample_criterion_fn=..., unbiased_gradients=..., num_transitions_per_observation=..., particles_dim=..., seed=..., name=...): # -> tuple[Any, Any]:
  """Use particle filtering to sample from the posterior over trajectories.

  ${particle_filter_arg_str}
    seed: PRNG seed; see `tfp.random.sanitize_seed` for details.
    name: Python `str` name for ops created by this method.
      Default value: `None` (i.e., `'infer_trajectories'`).
  Returns:
    trajectories: a (structure of) Tensor(s) matching the latent state, each
      of shape
      `concat([[num_timesteps, num_particles, b1, ..., bN], event_shape])`,
      representing unbiased samples from the posterior distribution
      `p(latent_states | observations)`.
    incremental_log_marginal_likelihoods: float `Tensor` of shape
      `[num_observation_steps, b1, ..., bN]`,
      giving the natural logarithm of an unbiased estimate of
      `p(observations[t] | observations[:t])` at each timestep `t`. Note that
      (by [Jensen's inequality](
      https://en.wikipedia.org/wiki/Jensen%27s_inequality))
      this is *smaller* in expectation than the true
      `log p(observations[t] | observations[:t])`.

  #### Examples

  **Tracking unknown position and velocity**: Let's consider tracking an object
  moving in a one-dimensional space. We'll define a dynamical system
  by specifying an `initial_state_prior`, a `transition_fn`,
  and `observation_fn`.

  The structure of the latent state space is determined by the prior
  distribution. Here, we'll define a state space that includes the object's
  current position and velocity:

  ```python
  initial_state_prior = tfd.JointDistributionNamed({
      'position': tfd.Normal(loc=0., scale=1.),
      'velocity': tfd.Normal(loc=0., scale=0.1)})
  ```

  The `transition_fn` specifies the evolution of the system. It should
  return a distribution over latent states of the same structure as the prior.
  Here, we'll assume that the position evolves according to the velocity,
  with a small random drift, and the velocity also changes slowly, following
  a random drift:

  ```python
  def transition_fn(_, previous_state):
    return tfd.JointDistributionNamed({
        'position': tfd.Normal(
            loc=previous_state['position'] + previous_state['velocity'],
            scale=0.1),
        'velocity': tfd.Normal(loc=previous_state['velocity'], scale=0.01)})
  ```

  The `observation_fn` specifies the process by which the system is observed
  at each time step. Let's suppose we observe only a noisy version of the =
  current position.

  ```python
    def observation_fn(_, state):
      return tfd.Normal(loc=state['position'], scale=0.1)
  ```

  Now let's track our object. Suppose we've been given observations
  corresponding to an initial position of `0.4` and constant velocity of `0.01`:

  ```python
  # Generate simulated observations.
  observed_positions = tfd.Normal(loc=tf.linspace(0.4, 0.8, 0.01),
                                  scale=0.1).sample()

  # Run particle filtering to sample plausible trajectories.
  (trajectories,  # {'position': [40, 1000], 'velocity': [40, 1000]}
   lps) = tfp.experimental.mcmc.infer_trajectories(
            observations=observed_positions,
            initial_state_prior=initial_state_prior,
            transition_fn=transition_fn,
            observation_fn=observation_fn,
            num_particles=1000)
  ```

  For all `i`, `trajectories['position'][:, i]` is a sample from the
  posterior over position sequences, given the observations:
  `p(state[0:T] | observations[0:T])`. Often, the sampled trajectories
  will be highly redundant in their earlier timesteps, because most
  of the initial particles have been discarded through resampling
  (this problem is known as 'particle degeneracy'; see section 3.5 of
  [Doucet and Johansen][1]).
  In such cases it may be useful to also consider the series of *filtering*
  distributions `p(state[t] | observations[:t])`, in which each latent state
  is inferred conditioned only on observations up to that point in time; these
  may be computed using `tfp.mcmc.experimental.particle_filter`.

  #### References

  [1] Arnaud Doucet and Adam M. Johansen. A tutorial on particle
      filtering and smoothing: Fifteen years later.
      _Handbook of nonlinear filtering_, 12(656-704), 2009.
      https://www.stats.ox.ac.uk/~doucet/doucet_johansen_tutorialPF2011.pdf
  [2] Adam Scibior, Vaden Masrani, and Frank Wood. Differentiable Particle
      Filtering without Modifying the Forward Pass. _arXiv preprint
      arXiv:2106.10314_, 2021. https://arxiv.org/abs/2106.10314

  """
  ...

def sequential_monte_carlo(initial_weighted_particles, propose_and_update_log_weights_fn, num_steps, resample_fn, resample_criterion_fn, trace_fn, trace_criterion_fn, particles_dim=..., parallel_iterations=..., unbiased_gradients=..., static_trace_allocation_size=..., seed=..., name=...):
  """Run Sequential Monte Carlo.

  Sequential Monte Carlo maintains a population of weighted particles
  representing samples from a sequence of target distributions.

  Args:
    initial_weighted_particles: The initial
      `tfp.experimental.mcmc.WeightedParticles`.
    propose_and_update_log_weights_fn: Python `callable` with signature
      `new_weighted_particles = propose_and_update_log_weights_fn(step,
      weighted_particles, seed=None)`. Its input is a
      `tfp.experimental.mcmc.WeightedParticles` structure representing
      weighted samples (with normalized weights) from the `step`th
      target distribution, and it returns another such structure representing
      unnormalized weighted samples from the next (`step + 1`th) target
      distribution. This will typically include particles
      sampled from a proposal distribution `q(x[step + 1] | x[step])`, and
      weights that account for some or all of: the proposal density,
      a transition density `p(x[step + 1] | x[step]),
      observation weights `p(y[step + 1] | x[step + 1])`, and/or a backwards
      or 'L'-kernel `L(x[step] | x[step + 1])`. The (log) normalization
      constant of the weights is interpreted as the incremental (log) marginal
      likelihood.
    num_steps: Number of steps to run Sequential Monte Carlo.
    resample_fn: Resampling scheme specified as a `callable` with signature
      `indices = resample_fn(log_probs, event_size, sample_shape, seed)`,
      where `log_probs` is a `Tensor` of the same shape as `state.log_weights`
      containing a normalized log-probability for every current
      particle, `event_size` is the number of new particle indices to
      generate,  `sample_shape` is the number of independent index sets to
      return, and the  return value `indices` is an `int` Tensor of shape
      `concat([sample_shape, [event_size, B1, ..., BN])`. Typically one of
      `tfp.experimental.mcmc.resample_deterministic_minimum_error`,
      `tfp.experimental.mcmc.resample_independent`,
      `tfp.experimental.mcmc.resample_stratified`, or
      `tfp.experimental.mcmc.resample_systematic`.
      Default value: `tfp.experimental.mcmc.resample_systematic`.
    resample_criterion_fn: optional Python `callable` with signature
      `do_resample = resample_criterion_fn(weighted_particles)`,
      passed an instance of `tfp.experimental.mcmc.WeightedParticles`. The
      return value `do_resample`
      determines whether particles are resampled at the current step. The
      default behavior is to resample particles when the effective
      sample size falls below half of the total number of particles.
      Default value: `tfp.experimental.mcmc.ess_below_threshold`.
    trace_fn: Python `callable` defining the values to be traced at each step,
      with signature `traced_values = trace_fn(weighted_particles, results)`
      in which the first argument is an instance of
      `tfp.experimental.mcmc.WeightedParticles` and the second an instance of
      `SequentialMonteCarloResults` tuple, and the return value is a structure
      of `Tensor`s.
      Default value: `lambda s, r: (s.particles, s.log_weights,
      r.parent_indices, r.incremental_log_marginal_likelihood)`
    trace_criterion_fn: optional Python `callable` with signature
      `trace_this_step = trace_criterion_fn(weighted_particles, results)`
      taking the same arguments as `trace_fn` and returning a boolean `Tensor`.
      If `None`, only values from the final step are returned.
      Default value: `lambda *_: True` (trace every step).
    particles_dim: `int` dimension that indexes the particles in the
      `tfp.experimental.mcmc.WeightedParticles` structures on which this
      function operates.
      Default value: `0`.
    parallel_iterations: Passed to the internal `tf.while_loop`.
      Default value: `1`.
    unbiased_gradients: If `True`, use the stop-gradient
      resampling trick of Scibior, Masrani, and Wood [1] to correct for
      gradient bias introduced by the discrete resampling step. This will
      generally increase the variance of stochastic gradients.
      Default value: `True`.
    static_trace_allocation_size: Optional Python `int` size of trace to
      allocate statically. This should be an upper bound on the number of steps
      traced and is used only when the length cannot be
      statically inferred (for example, if a `trace_criterion_fn` is
      specified).
      It is primarily intended for contexts where static shapes are required,
      such as in XLA-compiled code.
      Default value: `None`.
    seed: PRNG seed; see `tfp.random.sanitize_seed` for details.
    name: Python `str` name for ops created by this method.
      Default value: `None` (i.e., `'particle_filter'`).
  Returns:
    traced_results: A structure of Tensors as returned by `trace_fn`. If
      `trace_criterion_fn==None`, this is computed from the final step;
      otherwise, each Tensor will have initial dimension `num_steps_traced`
      and stacks the traced results across all steps.

  #### References

  [1] Adam Scibior, Vaden Masrani, and Frank Wood. Differentiable Particle
      Filtering without Modifying the Forward Pass. _arXiv preprint
      arXiv:2106.10314_, 2021. https://arxiv.org/abs/2106.10314
  """
  ...

@docstring_util.expand_docstring(particle_filter_arg_str=particle_filter_arg_str.format(scibor_ref_idx=1))
def particle_filter(observations, initial_state_prior, transition_fn, observation_fn, num_particles, initial_state_proposal=..., proposal_fn=..., resample_fn=..., resample_criterion_fn=..., unbiased_gradients=..., rejuvenation_kernel_fn=..., num_transitions_per_observation=..., particles_dim=..., trace_fn=..., trace_criterion_fn=..., static_trace_allocation_size=..., parallel_iterations=..., seed=..., name=...):
  """Samples a series of particles representing filtered latent states.

  The particle filter samples from the sequence of "filtering" distributions
  `p(state[t] | observations[:t])` over latent
  states: at each point in time, this is the distribution conditioned on all
  observations *up to that time*. Because particles may be resampled, a
  particle at time `t` may be different from the particle with the same index
  at time `t + 1`. To reconstruct trajectories by tracing back through the
  resampling process, see `tfp.mcmc.experimental.reconstruct_trajectories`.

  ${particle_filter_arg_str}
    trace_fn: Python `callable` defining the values to be traced at each step,
      with signature `traced_values = trace_fn(weighted_particles, results)`
      in which the first argument is an instance of
      `tfp.experimental.mcmc.WeightedParticles` and the second an instance of
      `SequentialMonteCarloResults` tuple, and the return value is a structure
      of `Tensor`s.
      Default value: `lambda s, r: (s.particles, s.log_weights,
      r.parent_indices, r.incremental_log_marginal_likelihood)`
    trace_criterion_fn: optional Python `callable` with signature
      `trace_this_step = trace_criterion_fn(weighted_particles, results)` taking
      the same arguments as `trace_fn` and returning a boolean `Tensor`. If
      `None`, only values from the final step are returned.
      Default value: `lambda *_: True` (trace every step).
    static_trace_allocation_size: Optional Python `int` size of trace to
      allocate statically. This should be an upper bound on the number of steps
      traced and is used only when the length cannot be
      statically inferred (for example, if a `trace_criterion_fn` is specified).
      It is primarily intended for contexts where static shapes are required,
      such as in XLA-compiled code.
      Default value: `None`.
    parallel_iterations: Passed to the internal `tf.while_loop`.
      Default value: `1`.
    seed: PRNG seed; see `tfp.random.sanitize_seed` for details.
    name: Python `str` name for ops created by this method.
      Default value: `None` (i.e., `'particle_filter'`).
  Returns:
    traced_results: A structure of Tensors as returned by `trace_fn`. If
      `trace_criterion_fn==None`, this is computed from the final step;
      otherwise, each Tensor will have initial dimension `num_steps_traced`
      and stacks the traced results across all steps.

  #### References

  [1] Adam Scibior, Vaden Masrani, and Frank Wood. Differentiable Particle
      Filtering without Modifying the Forward Pass. _arXiv preprint
      arXiv:2106.10314_, 2021. https://arxiv.org/abs/2106.10314
  """
  ...

def reconstruct_trajectories(particles, parent_indices, particles_dim=..., name=...):
  """Reconstructs the ancestor trajectory that generated each final particle."""
  ...

def smc_squared(observations, initial_parameter_prior, inner_initial_state_prior, inner_transition_fn, observation_fn, num_outer_particles, num_inner_particles, initial_parameter_proposal=..., parameter_proposal_kernel=..., inner_initial_state_proposal=..., inner_proposal_fn=..., outer_rejuvenation_criterion_fn=..., inner_resample_criterion_fn=..., inner_resample_fn=..., outer_trace_fn=..., outer_trace_criterion_fn=..., parallel_iterations=..., num_transitions_per_observation=..., static_trace_allocation_size=..., unbiased_gradients=..., seed=...):
  """SMC^2."""
  ...

