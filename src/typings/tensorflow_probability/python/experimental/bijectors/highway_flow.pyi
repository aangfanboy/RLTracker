"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.bijectors import bijector

"""Highway Flow bijector."""
__all__ = ['build_trainable_highway_flow', 'HighwayFlow']
def build_trainable_highway_flow(width, residual_fraction_initial_value=..., activation_fn=..., gate_first_n=..., seed=..., validate_args=...): # -> HighwayFlow:
  """Builds a HighwayFlow parameterized by trainable variables.

  The variables are transformed to enforce the following parameter constraints:

  - `residual_fraction` is bounded between 0 and 1.
  - `upper_diagonal_weights_matrix` is a randomly initialized (lower) diagonal
     matrix with positive diagonal of size `width x width`.
  - `lower_diagonal_weights_matrix` is a randomly initialized lower diagonal
     matrix with ones on the diagonal of size `width x width`;
  - `bias` is a randomly initialized vector of size `width`.

  Args:
    width: Input dimension of the bijector.
    residual_fraction_initial_value: Initial value for gating parameter, must be
      between 0 and 1.
    activation_fn: Callable invertible activation function
      (e.g., `tf.nn.softplus`), or `None`.
    gate_first_n: Decides which part of the input should be gated (useful for
      example when using auxiliary variables).
    seed: Seed for random initialization of the weights.
    validate_args: Python `bool`. Whether to validate input with runtime
        assertions.
        Default value: `False`.

  Returns:
    trainable_highway_flow: The initialized bijector.
  """
  ...

class HighwayFlow(bijector.Bijector):
  """Implements an Highway Flow bijector [1].

  HighwayFlow interpolates the vector-valued input `X` with the transformations
  at each step of the bjiector. The Highway Flow can be used as building block
  for a Cascading flow [1] or as a generic normalizing flow.

  The transformation consists of a convex update between the input `X` and a
  linear transformation of `X` followed by activation with the form `g(A @
  X + b)`, where `g(.)` is a differentiable non-decreasing activation
  function, and `A` and `b` are weights.

  The convex update is regulated by a residual fraction `lam`
  constrained between 0 and 1. Conceptually, we'd like to represent the
  function:
  `Y = lam * X + (1 - lam) * g(A @ X + b)`.

  To make this transformation invertible, the bijector is split in three
  convex updates:
   - `Y1 = lam * X + (1 - lam) * L @ X`, with `L` lower diagonal matrix with
     ones on the diagonal;
   - `Y2 = lam * Y1 + (1 - lam) * (U @ Y1 + b)`, with `U` upper diagonal matrix
     with positive diagonal;
   - `Y = lam * Y2 + (1 - lam) * g(Y2)`.
  where the identity function is mixed in at each step to ensure invertibility.
  While this is not exactly equivalent to the original expression, it is
  'morally similar' in that it similarly specializes to the
  identity function when `lam = 1`.

  The function `build_trainable_highway_flow` helps initializing the bijector
  with the variables respecting the various constraints.

  For more details on Highway Flow and Cascading Flows see [1].

  #### Usage example
  ```python
  tfd = tfp.distributions
  tfb = tfp.bijectors

  dim = 4 # last input dimension

  bijector = build_trainable_highway_flow(dim, activation_fn=tf.nn.softplus)
  y = bijector.forward(x)  # forward mapping
  x = bijector.inverse(y)  # inverse mapping
  base = tfd.MultivariateNormalDiag(loc=tf.zeros(dim)) # Base distribution
  transformed_distribution = tfd.TransformedDistribution(base, bijector)
  ```

  #### References

  [1]: Ambrogioni, Luca, Gianluigi Silvestri, and Marcel van Gerven.
  "Automatic variational inference with cascading flows." arXiv preprint
  arXiv:2102.04801 (2021).
  """
  _cache = ...
  def __init__(self, residual_fraction, activation_fn, bias, upper_diagonal_weights_matrix, lower_diagonal_weights_matrix, gate_first_n, validate_args=..., name=...) -> None:
    """Initializes the HighwayFlow.

    Args:
      residual_fraction: Scalar `Tensor` used for the convex update, must be
        between 0 and 1.
      activation_fn: Callable invertible activation function
      (e.g., `tf.nn.softplus`), or `None`.
      bias: Bias vector.
      upper_diagonal_weights_matrix: Lower diagional matrix of size (width,
        width) with positive diagonal (is transposed to Upper diagonal within
        the bijector).
      lower_diagonal_weights_matrix: Lower diagonal matrix with ones on the main
        diagional.
      gate_first_n: Integer number of initial dimensions to gate using
        `residual_fraction`. A value of `None` defaults to gating all dimensions
        (`gate_first_n == width`). Other values specify that it is only
        necessary to be able to represent the identity function over some
        prefix of the transformed dimensions.
        Default value: `None`.
      validate_args: Python `bool`. Whether to validate input with runtime
        assertions.
        Default value: `False`.
      name: Python `str` name for ops created by this object.
    """
    ...
  
  @property
  def bias(self):
    ...
  
  @property
  def width(self):
    ...
  
  @property
  def residual_fraction(self):
    ...
  
  @property
  def upper_diagonal_weights_matrix(self):
    ...
  
  @property
  def lower_diagonal_weights_matrix(self):
    ...
  
  @property
  def activation_fn(self): # -> Any:
    ...
  
  @property
  def gate_first_n(self):
    ...
  
  @property
  def num_ungated(self):
    ...
  


