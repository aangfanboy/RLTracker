"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.math.psd_kernels import positive_semidefinite_kernel as psd_kernel

"""FeatureScaled kernel over continuous and embedded categorical data."""
class FeatureScaledWithEmbeddedCategorical(psd_kernel.AutoCompositeTensorPsdKernel):
  """`FeatureScaled` kernel for continuous and embedded categorical data.

  This kernel is an extension of `FeatureScaled` that handles categorical data
  (encoded as integers, not one-hot) in addition to continuous (float) data.
  `ContinuousAndCategoricalValues` structures, containing arrays of continuous
  and categorical data, are passed to the `apply`, `matrix` and `tensor`
  methods. The continuous inputs are scaled and then passed to the distance
  function, like in `FeatureScaled`. Categorical data, encoded as integers,
  is continuously embedded using `LinearOperator`s. When all `LinearOperator`s
  are either `LinearOperatorIdentity` or `LinearOperatorScaledIdentity`
  instances, this kernel is the same as `FeatureScaledWithCategorical`, though
  in that case the latter should be used since it will be more efficient.

  #### Examples

  Compute the kernel matrix on synthetic data.

  ```python
  import numpy as np

  continuous_dim = 3
  categorical_dim = 2

  # Define an ARD kernel that takes a structure of continuous and categorical
  # data as inputs, with randomly-sampled `continuous_scale_diag` values and
  # diagonal embeddings of categorical data.
  base_kernel = tfpk.MaternFiveHalves()
  continuous_scale_diag = np.random.uniform(size=[continuous_dim])

  # Categorical `scale_diag`s are passed as an iterable of `LinearOperator`s,
  # where each `LinearOperator` applies to a categorical feature and has number
  # of rows equivalent to the cardinality of that feature. Categorical data is
  # assumed to be represented as integers between 0 and `n - 1` inclusive, which
  # are used to index into the `inverse_scale_diag` vectors.
  num_categories = [5, 4]
  categorical_embedding_operators = [
      tf.linalg.LinearOperatorDiag(np.random.uniform(size=[n]))
      for n in num_categories]

  kernel = tfpke.FeatureScaledWithEmbeddedCategorical(
      base_kernel,
      categorical_embedding_operators=categorical_embedding_operators,
      continuous_scale_diag=continuous_scale_diag,
      validate_args=True)

  # Create `num_points` examples in the continuous/categorical feature space.
  num_points = 12
  categorical_data_1 = np.stack(
      [np.random.randint(n, size=(num_points,)) for n in num_categories])
  categorical_data_2 = np.stack(
      [np.random.randint(n, size=(num_points,)) for n in num_categories])
  x1 = tfpke.ContinuousAndCategoricalValues(
      continuous=np.random.normal(size=(num_points, continuous_dim)),
      categorical=categorical_data_1)
  x2 = tfpke.ContinuousAndCategoricalValues(
      continuous=np.random.normal(size=(num_points, continuous_dim)),
      categorical=categorical_data_2)

  # Evaluate the kernel matrix for `x1` and `x2`.
  kernel.matrix(x1, x2)  # has shape `[num_points, num_points]`

  ```
  """
  def __init__(self, kernel, categorical_embedding_operators, continuous_scale_diag=..., continuous_inverse_scale_diag=..., feature_ndims=..., validate_args=..., name=...) -> None:
    """Construct an `FeatureScaledWithCategorical` kernel instance.

    Args:
      kernel: `PositiveSemidefiniteKernel` instance. Parameters to `kernel` must
        be broadcastable with `scale_diag`. `kernel` must be isotropic and
        implement an `_apply_with_distance` method.
      categorical_embedding_operators: Iterable of `LinearOperator` instances
        used to embed the categorical features. If the input categorical data
        has shape `[..., d]` and a single feature dimension, the iterable has
        length `d`.  Each `LinearOperator` has number of rows equal to the
        number of categories, and embeddings are equivalent to one-hot encoded
        categorical vectors multiplied by the densified `LinearOperator`.
        Euclidean distances are computed between the emeddings. If there are 0
        feature dimensions, the iterable should have length 1.
      continuous_scale_diag: Floating point array that control the
        sharpness/width of the kernel shape. Each `continuous_scale_diag` must
        have dimensionality of at least `kernel.feature_ndims.continuous`, and
        extra dimensions must be broadcastable with parameters of `kernel`.
        Default value: None.
      continuous_inverse_scale_diag: Non-negative floating point vectors that
        are treated as the reciprocals of the corresponding components of
        `continuous_scale_diag`.  Only one of `continuous_scale_diag` or
        `continuous_inverse_scale_diag` should be provided.
        Default value: None
      feature_ndims: `ContinuousAndCategoricalValues` instance containing
        integers indicating the rank of the continuous and categorical feature
        space. Default value: None, i.e. `kernel.feature_ndims` for both
        components of the feature space. Categorical `feature_ndims` > 1 is not
        supported.
      validate_args: If `True`, parameters are checked for validity despite
        possibly degrading runtime performance.
      name: Python `str` name prefixed to Ops created by this class.
    """
    ...
  
  @property
  def kernel(self): # -> Any:
    ...
  
  @property
  def continuous_scale_diag(self): # -> None:
    ...
  
  @property
  def continuous_inverse_scale_diag(self): # -> None:
    ...
  
  @property
  def categorical_embedding_operators(self): # -> Any:
    ...
  
  def continuous_inverse_scale_diag_parameters(self):
    ...
  


