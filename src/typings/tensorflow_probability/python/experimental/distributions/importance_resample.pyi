"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.distributions import distribution as distribution_lib

"""Meta-distribution to apply importance resampling to a proposal dist."""
class ImportanceResample(distribution_lib.Distribution):
  """Models the distribution of finitely many importance-reweighted samples.

  This wrapper adapts a proposal distribution towards a target density using
  [importance sampling](https://en.wikipedia.org/wiki/Importance_sampling).
  Given a proposal `q`, a target density `p` (which may be unnormalized), and
  an integer `importance_sample_size`, it models the result of the following
  sampling process:

  1. Draw `importance_sample_size` samples `z[k] ~ q` from the proposal.
  2. Compute an importance weight `w[k] = p(z[k]) / q(z[k])` for each sample.
  3. Return a sample `z[k*]` selected with probability proportional to
     the importance weights, i.e., with `k* ~ Categorical(probs=w/sum(w))`.

  In the limit where `importance_sample_size -> inf`, the result `z[k*]` of this
  procedure would be distributed according to the target density `p`. On the
  other hand, if `importance_sample_size == 1`, then the reweighting has no
  effect and the result `z[k*]` is simply a sample from `q`. Finite values
  of `importance_sample_size` describe distributions that are intermediate
  between `p` and `q`.

  This distribution may also be understood as an explicit representation of the
  surrogate posterior that is implicitly assumed by importance-weighted
  variational objectives. [1, 2]

  #### Examples

  This distribution can be used directly for posterior inference via importance
  sampling:

  ```python
  tfd = tfp.distributions
  tfed = tfp.experimental.distributions

  def target_log_prob_fn(x):
    prior = tfd.Normal(loc=0., scale=1.).log_prob(x)
    # Multimodal likelihood.
    likelihood = tf.reduce_logsumexp(
      tfd.Normal(loc=x, scale=0.1).log_prob([-1., 1.]))
    return prior + likelihood

  # Use importance sampling to infer an approximate posterior.
  approximate_posterior = tfed.ImportanceResample(
    proposal_distribution=tfd.Normal(loc=0., scale=2.),
    target_log_prob_fn=target_log_prob_fn,
    importance_sample_size=100)
  ```

  We can estimate posterior expectations directly using an importance-weighted
  sum of proposal samples:

  ```python
  # Directly compute expectations under the posterior via importance weights.
  posterior_mean = approximate_posterior.self_normalized_expectation(
    lambda x: x, importance_sample_size=1000)
  posterior_variance = approximate_posterior.self_normalized_expectation(
    lambda x: (x - posterior_mean)**2, importance_sample_size=1000)
  ```

  Alternately, the same expectations can be estimated from explicit (unweighted)
  samples. Note that sampling may be expensive because it performs resampling
  internally. For example, to produce `sample_size` samples requires first
  proposing values of shape `[sample_size, importance_sample_size]`
  (`[1000, 100]` in the code below) and then resampling down to `[sample_size]`,
  throwing most of the proposals away. For this reason you should prefer calling
  `self_normalized_expectation` over naive sampling to compute expectations.

  ```python
  posterior_samples = approximate_posterior.sample(1000)
  posterior_mean_inefficient = tf.reduce_mean(posterior_samples)
  posterior_variance_inefficient = tf.math.reduce_variance(posterior_samples)

  # Calling `self_normalized_expectation` allows for a much lower `sample_size`
  # because it uses the full set of `importance_sample_size` proposal samples to
  # approximate the expectation at each of the `sample_size` Monte Carlo
  # evaluations. This is formalized in Eq. 9 of [3].
  posterior_mean_efficient = approximate_posterior.self_normalized_expectation(
    lambda x: x, sample_size=10)
  posterior_variance_efficient = (
    approximate_posterior.self_normalized_expectation(
      lambda x: (x - posterior_mean_efficient)**2, sample_size=10))
  ```

  The posterior (log-)density cannot be computed directly, but may be
  stochastically approximated. The `prob` and `log_prob` methods accept
  arguments `seed` and `sample_size` to control the variance of the
  approximation.

  ```python
  # Plot the posterior density.
  from matplotlib import pylab as plt
  xs = tf.linspace(-3., 3., 101)
  probs = approximate_posterior.prob(xs, sample_size=10, seed=(42, 42))
  plt.plot(xs, probs)
  ```

  #### Connections to importance-weighted variational inference

  Optimizing an importance-weighted variational bound provides a natural
  approach to choose a proposal distribution for importance sampling.
  Importance-weighted bounds are available directly in TFP via the
  `importance_sample_size` argument to `tfp.vi.monte_carlo_variational_loss`
  and `tfp.vi.fit_surrogate_posterior`. For example, we might improve on the
  example above by replacing the fixed proposal distribution with a learned
  proposal:

  ```python
  proposal_distribution = tfp.experimental.util.make_trainable(tfd.Normal)
  importance_sample_size = 100
  importance_weighted_losses = tfp.vi.fit_surrogate_posterior(
    target_log_prob_fn,
    surrogate_posterior=proposal_distribution,
    optimizer=tf_keras.optimizers.Adam(0.1),
    num_steps=200,
    importance_sample_size=importance_sample_size)
  approximate_posterior = tfed.ImportanceResample(
    proposal_distribution=proposal_distribution,
    target_log_prob_fn=target_log_prob_fn,
    importance_sample_size=importance_sample_size)
  ```

  Note that although the importance-resampled `approximate_posterior` serves
  ultimately as the surrogate posterior, only the bare proposal distribution
  is passed as the `surrogate_posterior` argument to `fit_surrogate_posterior`.
  This is because the `importance_sample_size` argument tells
  `fit_surrogate_posterior` to compute an importance-weighted bound directly
  from the proposal distribution. Mathematically, it would be equivalent to omit
  the `importance_sample_size` argument and instead pass an `ImportanceResample`
  distribution as the surrogate posterior:

  ```python
  equivalent_but_less_efficient_losses = tfp.vi.fit_surrogate_posterior(
    target_log_prob_fn,
    surrogate_posterior=tfed.ImportanceResample(
      proposal_distribution=proposal_distribution,
      target_log_prob_fn=target_log_prob_fn,
      importance_sample_size=importance_sample_size),
    optimizer=tf_keras.optimizers.Adam(0.1),
    num_steps=200)
  ```

  but this approach is not recommended, because it performs redundant
  evaluations of the `target_log_prob_fn` compared to the direct bound shown
  above.

  #### References

  [1] Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance Weighted
      Autoencoders. In _International Conference on Learning
      Representations_, 2016. https://arxiv.org/abs/1509.00519
  [2] Chris Cremer, Quaid Morris, and David Duvenaud. Reinterpreting
      Importance-Weighted Autoencoders. In _International Conference on Learning
      Representations_, Workshop track, 2017. https://arxiv.org/abs/1704.02916
  [3] Justin Domke, Daniel Sheldon. Importance Weighting and Variational
      Inference. In _Neural Information Processing Systems (NIPS)_, 2018.
      https://arxiv.org/abs/1808.09034
  """
  def __init__(self, proposal_distribution, target_log_prob_fn, importance_sample_size, sample_size=..., stochastic_approximation_seed=..., validate_args=..., name=...) -> None:
    """Initialize an importance-resampled distribution.

    Args:
      proposal_distribution: Instance of `tfd.Distribution` used to generate
        proposals. This may be a joint distribution.
      target_log_prob_fn: Python `callable` representation of a (potentially
        unnormalized) target log-density. This should accept samples from the
        proposal, i.e.,
        `lp = target_log_prob_fn(proposal_distribution.sample())`.
      importance_sample_size: integer `Tensor` number of proposals used in
        the distribution of a single sample. Larger values better
        approximate the target distribution, at the cost of increased
        computation and memory usage.
      sample_size: integer `Tensor` number of Monte Carlo samples used
        to reduce variance in stochastic methods such as `log_prob`, `prob`,
        and `self_normalized_expectation`. Note that increasing
        `importance_sample_size` leads to a more accurate approximation of the
        target distribution (reducing bias and variance), while increasing
        `sample_size` improves the precision of estimates under the intermediate
        distribution corresponding to a particular finite
        `importance_sample_size` (i.e., it reduces variance only and does not
        affect the sampling distribution). If unsure, it's generally safe to
        leave `sample_size` at its default value of `1` and focus on increasing
        `importance_sample_size` instead.
        Default value: `1`.
      stochastic_approximation_seed: optional PRNG key used in stochastic
        approximations for methods such as `log_prob`, `prob`,
        and `self_normalized_expectation`. This seed does not affect sampling.
        Default value: `None`.
      validate_args: Python `bool`.  Whether to validate input with asserts.
        If `validate_args` is `False`, and the inputs are invalid,
        correct behavior is not guaranteed.
        Default value: `False`.
      name: Python `str` name for this distribution. If `None`, defaults to
        'importance_resample'.
        Default value: `None`.
    """
    ...
  
  @property
  def proposal_distribution(self): # -> Any:
    ...
  
  @property
  def importance_sample_size(self):
    ...
  
  @property
  def sample_size(self):
    ...
  
  @property
  def stochastic_approximation_seed(self): # -> None:
    ...
  
  @property
  def target_log_prob_fn(self): # -> Any:
    ...
  
  def self_normalized_expectation(self, fn, importance_sample_size=..., sample_size=..., seed=..., name=...):
    """Approximates the expectation of fn(x).

    This function applies self-normalized importance sampling with the given
    proposal distribution to approximate expectations under the target
    distribution. By using all of the `importance_sample_size` proposal
    samples to approximate the expectation, this will in general give
    lower-variance estimates than those obtained by explicit sampling
    (`tf.reduce_sum(fn(self.sample(sample_size)), axis=0)`), since the latter
    returns only one point from each set of `importance_sample_size` proposals.

    Concretely, this function draws `importance_sample_size` samples
    `x[1], x[2], ...` from
    `self.proposal_distribution`, computes their importance weights
    `w[k] = target_log_prob_fn(x[k]) / proposal_distribution.log_prob(x[k])`,
    and returns the weighted sum
    `sum(w[k]/sum(w) * fn(x[k]) for k in range(importance_sample_size))`. If
    `sample_size > 1` is specified, the previous procedure is performed
    multiple times and the results averaged to reduce variance.

    Note: to approximate expectations under the target distribution you should
    prefer to increase `importance_sample_size` (which reduces
    both bias and variance) rather than `sample_size` (which reduces variance
    only). Values of `sample_size > 1` are needed only if you specifically want
    expectations under the intermediate distribution that arises from
    considering a particular finite number of importance samples.

    Args:
      fn: Python `callable` that takes samples from `self.proposal_distribution`
        and returns a (structure of) `Tensor` value(s). This may represent a
        prediction derived from a posterior sample, or even a simple statistic;
        for example, the expectation of `fn = lambda x: x` is the posterior
        mean.
      importance_sample_size: int `Tensor` number of samples used to define the
        distribution under which the expectation is taken. If `None`, defaults
        to `self.importance_sample_size`.
        Default value: `None`.
      sample_size: int `Tensor` number of samples used to reduce variance in the
        expectation for a given `importance_sample_size`. If `None`, defaults
        to `self.sample_size`.
        Default value: `None`.
      seed: PRNG seed; see `tfp.random.sanitize_seed` for details. If `None`,
        defaults to `self.stochastic_approximation_seed`.
        Default value: `None`.
      name: Python string name for ops created by this function.
        Default value: `self_normalized_expectation`.
    Returns:
      expected_value: (structure of) `Tensor` value(s) estimate of the
        expectation of `fn(x)` under the target distribution.
    """
    ...
  


