"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.distributions import distribution

"""Parameter estimation by iterated filtering."""
__all__ = ['geometric_cooling_schedule', 'IteratedFilter']
JAX_MODE = ...
NUMPY_MODE = ...
_copy_structure = ...
ParametersAndState = ...
def geometric_cooling_schedule(cooling_fraction_per_k_iterations, k=...): # -> Callable[..., Any]:
  """Defines a cooling schedule following a geometric sequence.

  This returns a function `f` such that

  ```python
  f(iteration) = cooling_fraction_per_k_iterations**(iteration / k)
  ```

  Args:
    cooling_fraction_per_k_iterations: float `Tensor` ratio by which the
      original value should be scaled once `k` iterations have been completed.
    k: int `Tensor` number of iterations used to define the schedule.
  Returns:
    f: Python `callable` representing the cooling schedule.
  """
  ...

class DeterministicEmpirical(distribution.Distribution):
  """Dummy 'proposal' distribution that just returns samples we pass in."""
  def __init__(self, values_with_sample_dim, batch_ndims=..., validate_args=..., name=...) -> None:
    """Initializes an empirical distribution with a list of samples.

    Args:
      values_with_sample_dim: nested structure of `Tensor`s, each of shape
        prefixed by `[num_samples, B1, ..., Bn]`, where `num_samples` as well as
        `B1, ..., Bn` are batch dimensions shared across all `Tensor`s.
      batch_ndims: optional scalar int `Tensor`, or structure matching
        `values_with_sample_dim` of scalar int `Tensor`s, specifying the number
        of batch dimensions. Used to determine the batch and event shapes of the
        distribution.
        Default value: `0`.
      validate_args: Python `bool` indicating whether to perform runtime checks
        that may have performance cost.
        Default value: `False`.
      name: Python `str` name for ops created by this distribution.
    """
    ...
  
  @property
  def batch_ndims(self):
    ...
  
  @property
  def max_num_samples(self):
    ...
  
  @property
  def values_with_sample_dim(self):
    ...
  
  def sample(self, sample_shape=..., seed=..., name=...):
    ...
  


def augment_transition_fn_with_parameters(parameter_prior, parameterized_transition_fn, parameter_constraining_bijector): # -> Callable[..., JointDistributionNamed]:
  """Wraps a transition fn on states to act on `ParametersAndState` tuples."""
  ...

def augment_observation_fn_with_parameters(parameterized_observation_fn, parameter_constraining_bijector): # -> Callable[..., Any]:
  """Augments an observation fn to take `ParametersAndState` namedtuples."""
  ...

def joint_prior_on_parameters_and_state(parameter_prior, parameterized_initial_state_prior_fn, parameter_constraining_bijector, prior_is_constrained=...): # -> JointDistributionNamed:
  """Constructs a joint dist. from p(parameters) and p(state | parameters)."""
  ...

class IteratedFilter:
  """A model augmented with parameter perturbations for iterated filtering."""
  def __init__(self, parameter_prior, parameterized_initial_state_prior_fn, parameterized_transition_fn, parameterized_observation_fn, parameterized_initial_state_proposal_fn=..., parameterized_proposal_fn=..., parameter_constraining_bijector=..., name=...) -> None:
    """Builds an iterated filter for parameter estimation in sequential models.

    Iterated filtering is a parameter estimation method in which parameters
    are included in an augmented state space, with dynamics that introduce
    parameter perturbations, and a filtering
    algorithm such as particle filtering is run several times with perturbations
    of decreasing size. This class implements the IF2 algorithm of
    [Ionides et al., 2015][1], for which, under appropriate conditions
    (including a uniform prior) the final parameter distribution approaches a
    point mass at the maximum likelihood estimate. If a non-uniform prior is
    provided, the final parameter distribution will (under appropriate
    conditions) approach a point mass at the maximum a posteriori (MAP) value.

    This class augments the state space of a sequential model to include
    parameter perturbations, and provides utilities to run particle filtering
    on that augmented model. Alternately, the augmented components may be passed
    directly into a filtering algorithm of the user's choice.

    Args:
      parameter_prior: prior `tfd.Distribution` over parameters (may be a joint
        distribution).
      parameterized_initial_state_prior_fn: `callable` with signature
        `initial_state_prior = parameterized_initial_state_prior_fn(parameters)`
        where `parameters` has the form of a sample from `parameter_prior`,
        and `initial_state_prior` is a distribution over the initial state.
      parameterized_transition_fn: `callable` with signature
        `next_state_dist = parameterized_transition_fn(
        step, state, parameters, **kwargs)`.
      parameterized_observation_fn: `callable` with signature
        `observation_dist = parameterized_observation_fn(
        step, state, parameters, **kwargs)`.
      parameterized_initial_state_proposal_fn: optional `callable` with
        signature `initial_state_proposal =
        parameterized_initial_state_proposal_fn(parameters)` where `parameters`
        has the form of a sample from `parameter_prior`, and
        `initial_state_proposal` is a distribution over the initial state.
      parameterized_proposal_fn: optional `callable` with signature
        `next_state_dist = parameterized_transition_fn(
        step, state, parameters, **kwargs)`.
        Default value: `None`.
      parameter_constraining_bijector: optional `tfb.Bijector` instance
        such that `parameter_constraining_bijector.forward(x)` returns valid
        parameters for any real-valued `x` of the same structure and shape
        as `parameters`. If `None`, the default bijector of the provided
        `parameter_prior` will be used.
        Default value: `None`.
      name: `str` name for ops constructed by this object.
        Default value: `iterated_filter`.

    #### Example

    We'll walk through applying iterated filtering to a toy
    Susceptible-Infected-Recovered (SIR) model, a [compartmental model](
    https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIR_model)
    of infectious disease. Note that the model we use here is extremely
    simplified and is intended as a pedagogical example; it should not be
    interpreted to describe disease spread in the real world.

    We begin by specifying a prior distribution over the parameters to be
    inferred, thus defining the structure of the parameter space and the support
    of the parameters (which will imply a default constraining bijector). Here
    we'll use uniform priors over ranges that we expect to contain the
    parameters:

    ```python
    parameter_prior = tfd.JointDistributionNamed({
        'infection_rate': tfd.Uniform(low=0., high=3.),
        'recovery_rate': tfd.Uniform(low=0., high=3.),
    })
    ```

    The model specification itself is identical to that used by
    `tfp.experimental.mcmc.infer_trajectories`, except that each component
    accepts an additional `parameters` keyword argument. We start by specifying
    a parameterized prior on initial states. In this case, our state
    includes the current number of susceptible and infected individuals
    (the third compartment, recovered individuals, is implicitly defined
    to include the remaining population). We'll also include, as auxiliary
    variables, the daily counts of new infections and new recoveries; these
    will help ensure that people shift consistently across compartments.

    ```python
    population_size = 1000
    initial_state_prior_fn = lambda parameters: tfd.JointDistributionNamed({
        'new_infections': tfd.Poisson(parameters['infection_rate']),
        'new_recoveries': tfd.Deterministic(
            tf.broadcast_to(0., tf.shape(parameters['recovery_rate']))),
        'susceptible': (lambda new_infections:
                        tfd.Deterministic(population_size - new_infections)),
        'infected': (lambda new_infections:
                     tfd.Deterministic(new_infections))})
    ```

    **Note**: the state prior must have the same batch shape as the
    passed-in parameters; equivalently, it must sample a full state for each
    parameter particle. If any part of the state prior does not depend
    on the parameters, you must manually ensure that it has the appropriate
    batch shape. For example, in the definition of `new_recoveries` above,
    applying `broadcast_to` with the shape of a parameter ensures that
    the batch shape is maintained.

    Next, we specify a transition model. This takes the state at the
    previous day, along with parameters, and returns a distribution
    over the state for the current day.

    ```python
    def parameterized_infection_dynamics(_, previous_state, parameters):
      new_infections = tfd.Poisson(
          parameters['infection_rate'] * previous_state['infected'] *
          previous_state['susceptible'] / population_size)
      new_recoveries = tfd.Poisson(
          previous_state['infected'] * parameters['recovery_rate'])
      return tfd.JointDistributionNamed({
          'new_infections': new_infections,
          'new_recoveries': new_recoveries,
          'susceptible': lambda new_infections: tfd.Deterministic(
            tf.maximum(0., previous_state['susceptible'] - new_infections)),
          'infected': lambda new_infections, new_recoveries: tfd.Deterministic(
            tf.maximum(0.,
                       (previous_state['infected'] +
                        new_infections - new_recoveries)))})
    ```

    Finally, assume that every day we get to observe noisy counts of new
    infections and recoveries.

    ```python
    def parameterized_infection_observations(_, state, parameters):
      del parameters  # Not used.
      return tfd.JointDistributionNamed({
          'new_infections': tfd.Poisson(state['new_infections'] + 0.1),
          'new_recoveries': tfd.Poisson(state['new_recoveries'] + 0.1)})
    ```

    Combining these components, an `IteratedFilter` augments
    the state space to include parameters that may change over time.

    ```python
    iterated_filter = tfp.experimental.sequential.IteratedFilter(
      parameter_prior=parameter_prior,
      parameterized_initial_state_prior_fn=initial_state_prior_fn,
      parameterized_transition_fn=parameterized_infection_dynamics,
      parameterized_observation_fn=parameterized_infection_observations)
    ```

    We may then run the filter to estimate parameters from a series
    of observations:

    ```python
     # Simulated with `infection_rate=1.2` and `recovery_rate=0.1`.
     observed_values = {
       'new_infections': tf.convert_to_tensor([
          2., 7., 14., 24., 45., 93., 160., 228., 252., 158.,  17.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),
       'new_recoveries': tf.convert_to_tensor([
          0., 0., 3., 4., 3., 8., 12., 31., 49., 73., 85., 65., 71.,
          58., 42., 65., 36., 31., 32., 27., 31., 20., 19., 19., 14., 27.])
     }
     parameter_particles = iterated_filter.estimate_parameters(
         observations=observed_values,
         num_iterations=20,
         num_particles=4096,
         initial_perturbation_scale=1.0,
         cooling_schedule=(
             tfp.experimental.sequential.geometric_cooling_schedule(
                 0.001, k=20)),
         seed=test_util.test_seed())
     print('Mean of parameter particles from final iteration: {}'.format(
       tf.nest.map_structure(lambda x: tf.reduce_mean(x[-1], axis=0),
                             parameter_particles)))
     print('Standard deviation of parameter particles from '
           'final iteration: {}'.format(
           tf.nest.map_structure(lambda x: tf.math.reduce_std(x[-1], axis=0),
                                 parameter_particles)))
    ```

    For more control, we could alternately choose to run filtering iterations
    on the augmented model manually, using the filter of our choice.
    For example, manually invoking `infer_trajectories` would allow us
    to inspect the parameter and state values at all timesteps, and their
    corresponding log-probabilities:

    ```python
    trajectories, lps = tfp.experimental.mcmc.infer_trajectories(
      observations=observations,
      initial_state_prior=iterated_filter.joint_initial_state_prior,
      transition_fn=functools.partial(
          iterated_filter.joint_transition_fn,
          perturbation_scale=perturbation_scale),
      observation_fn=iterated_filter.joint_observation_fn,
      proposal_fn=iterated_filter.joint_proposal_fn,
      initial_state_proposal=iterated_filter.joint_initial_state_proposal(
          initial_unconstrained_parameters),
      num_particles=4096)
    ```

    #### References:

    [1] Edward L. Ionides, Dao Nguyen, Yves Atchade, Stilian Stoev, and Aaron A.
    King. Inference for dynamic and latent variable models via iterated,
    perturbed Bayes maps. _Proceedings of the National Academy of Sciences_
    112, no. 3: 719-724, 2015.
    https://www.pnas.org/content/pnas/112/3/719.full.pdf
    """
    ...
  
  @property
  def batch_ndims(self):
    ...
  
  @property
  def joint_initial_state_prior(self): # -> JointDistributionNamed:
    """Initial state prior for the joint (augmented) model."""
    ...
  
  def joint_initial_state_proposal(self, initial_unconstrained_parameters=...): # -> JointDistributionNamed | None:
    """Proposal to initialize the model with given parameter particles."""
    ...
  
  @property
  def joint_transition_fn(self): # -> Callable[..., JointDistributionNamed]:
    """Transition function for the joint (augmented) model."""
    ...
  
  @property
  def joint_observation_fn(self): # -> Callable[..., Any]:
    """Observation function for the joint (augmented) model."""
    ...
  
  @property
  def joint_proposal_fn(self): # -> Callable[..., JointDistributionNamed] | None:
    """Proposal function for the joint (augmented) model."""
    ...
  
  @property
  def name(self): # -> str:
    ...
  
  @property
  def parameter_constraining_bijector(self):
    """Bijector mapping unconstrained real values into the parameter space."""
    ...
  
  @property
  def parameterized_initial_state_prior_fn(self): # -> Any:
    """Prior function that was passed in at construction."""
    ...
  
  @property
  def parameterized_initial_state_proposal_fn(self): # -> Any:
    """Initial proposal function passed in at construction."""
    ...
  
  @property
  def parameter_prior(self): # -> Any:
    """Prior distribution on parameters passed in at construction."""
    ...
  
  def one_step(self, observations, perturbation_scale, num_particles, initial_unconstrained_parameters=..., seed=..., name=..., **kwargs):
    """Runs one step of filtering to sharpen parameter estimates.

    Args:
      observations: observed `Tensor` value(s) on which to condition the
        parameter estimate.
      perturbation_scale: scalar float `Tensor`, or any structure of float
        `Tensor`s broadcasting to the same shape as the unconstrained
        parameters, specifying the scale (standard deviation) of Gaussian
        perturbations to each parameter at each timestep.
      num_particles: scalar int `Tensor` number of particles to use. Must match
        the batch dimension of `initial_unconstrained_parameters`, if specified.
      initial_unconstrained_parameters: optional structure of `Tensor`s, of
        shape matching
        `self.joint_initial_state_prior.sample([
        num_particles]).unconstrained_parameters`,
        used to initialize the filter.
        Default value: `None`.
      seed: PRNG seed; see `tfp.random.sanitize_seed` for details.
      name: `str` name for ops constructed by this method.
      **kwargs: additional keyword arguments passed to
        `tfp.experimental.mcmc.infer_trajectories`.
    Returns:
      final_unconstrained_parameters: structure of `Tensor`s matching
        `initial_unconstrained_parameters`, containing samples of
        unconstrained parameters at the final timestep, as computed by
        `self.filter_fn`.
    """
    ...
  
  def estimate_parameters(self, observations, num_iterations, num_particles, initial_perturbation_scale, cooling_schedule, seed=..., name=..., **kwargs):
    """Runs multiple iterations of filtering following a cooling schedule.

    Args:
      observations: observed `Tensor` value(s) on which to condition the
        parameter estimate.
      num_iterations: int `Tensor` number of filtering iterations to run.
      num_particles: scalar int `Tensor` number of particles to use.
      initial_perturbation_scale: scalar float `Tensor`, or any structure of
        float `Tensor`s broadcasting to the same shape as the (unconstrained)
        parameters, specifying the scale (standard deviation) of Gaussian
        perturbations to each parameter at the first timestep.
      cooling_schedule: callable with signature
        `cooling_factor = cooling_schedule(iteration)` for `iteration` in
        `[0, ..., num_iterations - 1]`. The filter is
        invoked with perturbations of scale
        `initial_perturbation_scale * cooling_schedule(iteration)`.
      seed: PRNG seed; see `tfp.random.sanitize_seed` for details.
      name: `str` name for ops constructed by this method.
      **kwargs: additional keyword arguments passed to
        `tfp.experimental.mcmc.infer_trajectories`.
    Returns:
      final_parameter_particles: structure of `Tensor`s matching
        `self.parameter_prior`, each with batch shape
        `[num_iterations, num_particles]`. These are the populations
        of particles representing the parameter estimate after each iteration
        of filtering.
    """
    ...
  


