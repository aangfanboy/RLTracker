"""
This type stub file was generated by pyright.
"""

from tensorflow_probability.python.internal import tf_keras

"""VariableInputLayer."""
class VariableLayer(tf_keras.layers.Layer):
  """Simply returns a (trainable) variable, regardless of input.

  This layer implements the mathematical function `f(x) = c` where `c` is a
  constant, i.e., unchanged for all `x`. Like other Keras layers, the constant
  is `trainable`.  This layer can also be interpretted as the special case of
  `tf_keras.layers.Dense` when the `kernel` is forced to be the zero matrix
  (`tf.zeros`).

  #### Examples

  ```python
  trainable_normal = tf_keras.models.Sequential([
      tfp.layers.VariableLayer(
          shape=[3, 4, 2],
          dtype=tf.float64,
          initializer=tfp.layers.BlockwiseInitializer([
              'zeros',
              tf_keras.initializers.Constant(np.log(np.expm1(1.))),
          ], sizes=[1, 1])),
      tfp.layers.DistributionLambda(lambda t: tfd.Independent(
          tfd.Normal(loc=t[..., 0], scale=tf.math.softplus(t[..., 1])),
          reinterpreted_batch_ndims=1)),
  ])
  negloglik = lambda x, rv_x: -rv_x.log_prob(x)
  trainable_normal.compile(optimizer='adam', loss=negloglik)

  # trainable_normal.fit(dataset)

  x = trainable_normal(0.)  # `0.` ignored; like conditioning on emptyset.

  x.dtype
  # ==> tf.float64

  x.batch_shape
  # ==> [3]

  x.event_shape
  # ==> [4]

  x.mean()
  # ==> tf.reduce_mean(dataset)

  x.variance()
  # ==> tfp.stats.variance(dataset)
  ```

  """
  def __init__(self, shape, dtype=..., activation=..., initializer=..., regularizer=..., constraint=..., **kwargs) -> None:
    """Creates the `VariableLayer`.

    Args:
      shape: integer or integer vector specifying the shape of the output of
        this layer.
      dtype: TensorFlow `dtype` of the variable created by this layer.
        Default value: `None` (i.e., `tf.as_dtype(tf_keras.backend.floatx())`).
      activation: Activation function to use.  If you don't specify anything, no
        activation is applied (ie. "linear" activation: `a(x) = x`).
        Default value: `None`.
      initializer: Initializer for the `constant` vector. For example, to
        initialize a trainable (initially standard) `Normal` with
        `tf.math.softplus` transformed scale, one might use:
        ```python
        tfp.layers.BlockwiseInitializer([
            'zeros',
            tf_keras.initializers.Constant(np.log(np.expm1(1.))),  # = 0.541325
        ], sizes=[1, 1])
        ```
        Default value: `'zeros'`.
      regularizer: Regularizer function applied to the `constant` vector.
        Default value: `None`.
      constraint: Constraint function applied to the `constant` vector.
        Default value: `None`.
      **kwargs: Extra arguments forwarded to `tf_keras.layers.Layer`.
    """
    ...
  
  def call(self, _):
    ...
  


